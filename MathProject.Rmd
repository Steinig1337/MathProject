---
title: "MathProject"
author: "F D"
date: "26 12 2019"
output:
  rmdformats::readthedown:
    highlight: kate
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Load the packages

```{r}
library(tidyverse)
library(readxl)
library(shiny)
library(shinythemes)
library(lubridate)
```


# Welcome to the project for the math class

I will add the cutomer data to my harvest data and weather data and i will try to do a pca (pricipal component analyse), some clustering(k-nearest neightbour) and a linear regression on the data. I want to find some relationsships between selling of a product and the weather or some other relationship i dont know. So first of all i will combine the data into one big data frame. To do that we have to load all the different data and do some data wrangling. 

# Data Wrangling

## Load data

```{r}
selling_q3 <- read_xls("Data/Auszahlungen_2019-07-01_2019-09-30.xls")
selling_oct <- read_xls("Data/Auszahlungen_2019-10-01_2019-10-31.xls")
selling_nov <- read_xls("Data/Auszahlungen_2019-11-01_2019-11-30.xls")
product_q3 <- read_xls("Data/Verkaufe_pro_Angebot_2019-07-01_2019-09-30.xls")
product_oct <- read_xls("Data/Verkaufe_pro_Angebot_2019-10-01_2019-10-31.xls")
product_nov <- read_xls("Data/Verkaufe_pro_Angebot_2019-11-01_2019-11-30.xls")
customers_q3 <- read_xls("Data/Verkaufe_Rechnungen_2019-07-01_2019-09-30.xls")
customers_oct <- read_xls("Data/Verkaufe_Rechnungen_2019-10-01_2019-10-31.xls")
customers_nov <- read_xls("Data/Verkaufe_Rechnungen_2019-11-01_2019-11-30.xls")
weather <- read_delim("Data/produkt_klima_tag_20180704_20200104_02564.txt", ";", escape_double = FALSE, trim_ws = TRUE)
```

I loaded some data of my customers, my selling in generell and my selling of each product. So the selling data frame is for the generall selling informations. The produkt data frame is for the informations about each product and how often it got sold. The last data frame is called customers and it holds informations about the customers. Where they are from and how much they bought. And i forgot the weather data frame. It holds the weather information for each day.

## Combine the other months with the first three

To get the whole data we have to combine all the different months.

```{r}
customers <- list(customers_q3, customers_oct, customers_nov) %>%
  bind_rows()
product <- list(product_q3, product_oct, product_nov) %>%
  bind_rows()
selling <- list(selling_q3, selling_oct, selling_nov) %>%
  bind_rows()
```

## Delete the rest

Let's delete the data frames which aren't needed anymore. So the environment is tidied up.

```{r}
rm(customers_q3, customers_oct, customers_nov, product_q3, product_oct, product_nov, selling_q3, selling_oct, selling_nov)
```


## Delete columns which aren't needed

We have to tidy up some columns which are totally useless or the information is doubled.

```{r}
customers <- customers %>%
  select(-`Summe MwSt.`, -`Nummer der Schwärmerei`, -`Summe netto`)
product <- product %>%
  select(-`Summe MwSt.`, -`Summe netto`, -Produktkategorie, -`Produkt Unterkategorie`)
selling <- selling %>%
  select(-`Verkäufe - Mehrwertsteuer`, -`Verkäufe - Summe netto`, -`Servicegebühr - Mehrwertsteuersatz 19%`, -`Servicegebühr - wenn der Rechnungsempfänger die MwSt. nicht in Rechnung stellt`, -`Einkäufe - Summe netto`, -`Einkäufe - Mehrwertsteuer`)
weather <- weather %>%
  select(-STATIONS_ID, -QN_3, -QN_4, -SHK_TAG, -eor, -SDK)
```


## Replace different product names

Because i changed the product names in november i have to replace some product names so the same products have the same names.

```{r}
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Radieschen rot Microgreens unverpackt 40g", "Radieschen rot Microgreens unverpackt (1 × 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Kohlrabi rot Microgreens", "Kohlrabi rot Microgreens unverpackt (1 x 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("Brokkoli Microgreens unverpackt 40g - 40 g", "Brokkoli Microgreens unverpackt (1 x 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("Rote Bete Microgreens - 40 g", "Rote Bete Microgreens unverpackt (1 × 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Mizuna Microgreens unverpackt", "Mizuna Microgreens unverpackt (1 x 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Bockshornklee Microgreens unverpackt", "Bockshornklee Microgreens unverpackt (1 x 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Daikon Rettich unverpackt 40g", "Daikon Rettich unverpackt (1 × 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Radieschen rot Microgreens unverpackt 100g", "Radieschen rot Microgreens unverpackt (1 × 100 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Sonnenblumen Microgreens unverpackt 100g", "Sonnenblumen Microgreens unverpackt (1 × 100 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Sonnenblumen Microgreens unverpackt 40g", "Sonnenblumen Microgreens unverpackt (1 × 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("20g Koriander Microgreens unverpackt 20g", "Koriander Microgreens unverpackt (1 × 20 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("Erbsen Microgreens unverpackt 40g - 40 g", "Erbsen Microgreens unverpackt (1 × 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("Senf Microgreens unverpackt 40g (1 × 40 g)", "Senf Microgreens unverpackt (1 × 40 g)")
```


## Test of product names

```{r}
product %>%
  distinct(Produktname) %>%
  arrange(Produktname)
```

We see that there is still one name doubled. But i could't find the error so we have to use it like this.

## Lets replace different offernumbers

Here we have the same problem like for the productnames. So we have to replace some numbers that we get a equal number for the same product. If we don't do that we have lot's of different numbers for the same product and the analyse does't work very well.

```{r}
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("BMICR.fdaf.1", "BMU40.g3va.1")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("DRUNV.fino.1", "DRU40.g3vj.1")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("RROT.f9et.1", "RRMU4.g3vu.1")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("RRU10.fpiv.1", "RRMU4.g3vu.2")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("RRMU1.g3vr.2", "RRMU4.g3vu.2")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("SENF.f9ew.1", "SMU40.g3vw.1")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("SMUNV.finu.1", "SMU40.g3w1.1")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("SMU10.g3vz.1", "SMU40.g3w1.2")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("SMU10.foby.1", "SMU40.g3w1.2")


```

## Test the offernumbers

```{r}
product %>%
  distinct(Angebotsnummer, Produktname) %>%
  arrange(Produktname)
```

As you can see we have now only one offernumber for one product.

## Use lubridate to manipulate the date column

We have to have equal date columns to join the selling data with the weather data. So i use lubridate to change the date column to make easier to join the data.

```{r}
# customers$`Datum der Verteilung` <- ymd_hms(customers$`Datum der Verteilung`) maybe we have to extract only the date
weather$MESS_DATUM <- ymd(weather$MESS_DATUM)

customers <- customers %>%
  mutate(date = date(customers$`Datum der Verteilung`))
product <- product %>%
  mutate(date = date(product$`Datum der Verteilung`))
selling <- selling %>%
  mutate(date = date(selling$`Datum der Verteilung`))
weather <- weather %>%
  mutate(date = date(weather$MESS_DATUM))
```


## Let's add some weather data to the selling informations.

Let's add the weather information for the selling days. Maybe there is a correlation between bad weather and bad selling days. But we will join it in a new data frame so we can analyse the date with weather informations and without.

```{r}
customers_weather <- left_join(customers, weather, by = "date") 
# by = c("column1", "column2") so i don't have to create a new column with is equal in every data frame
product_weather <- left_join(product, weather, by = "date")
selling_weather <- left_join(selling, weather, by = "date")
```


## Let's have a look on the products

```{r}
product %>%
  group_by(Produktname) %>%
  summarise(Verkauft = sum(Menge), Erloes = sum(Gesamtbrutto)) %>%
  ggplot(aes(x = reorder(Produktname, Erloes), y = Erloes, fill = Erloes)) +
  geom_col() +
  coord_flip()
```

# Statistical analysis

I will try some methods we discussed in class on my data. After that I will look on the result and decide what to do next. Maybe we will get some nice dependencies or maybe not. First i will do some clustering with kmeans and k-Nearest Neighbour. After that i will try a principle component analysis and at least a linear regression. Hopefully i will learn something about my customers and we will get some interesting insights.



## kmeans clustering

Let's try to find some interesting clusters to discribe customer groups or something else. First i will try to get some clusters with the combined customer_weather data. We have to use numeric columns for clusters. So we have to explicid say with columns are used for the clustering. So let's try every column which is numeric. To view the clusters we can use ggplot with a 2d plot.

```{r}
km1 <- kmeans(x = customers_weather[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")], centers = 2)

df1 <- customers_weather

df1 <- bind_cols(df1, km = as.factor(km1$cluster))

df1 %>% 
  ggplot() +
  geom_point(aes(Gesamtbrutto, TNK, color = km)) +
  geom_point(data = as.data.frame(km1$centers), aes(Gesamtbrutto, TNK), size = 3)
```

We can see that this model doens't work very well. Lets try the others.

```{r}
km2 <- kmeans(x = product_weather[,c("Einzelpreis netto", "Menge", "Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")], centers = 2)

df2 <- product_weather

df2 <- bind_cols(df2, km = as.factor(km2$cluster))

df2 %>% 
  ggplot() +
  geom_point(aes(Gesamtbrutto, TNK, color = km)) +
  geom_point(data = as.data.frame(km2$centers), aes(Gesamtbrutto, TNK), size = 3)
```

Same visualization as the plot before.

```{r}
km3 <- kmeans(x = selling_weather[,c("Verkäufe - Gesamtbetrag", "Einkäufe - Gesamtbetrag", "Gesamtsumme", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")], centers = 3)

df3 <- selling_weather

df3 <- bind_cols(df3, km = as.factor(km3$cluster))

df3 %>% 
  ggplot() +
  geom_point(aes(Gesamtsumme, TNK, color = km)) +
  geom_point(data = as.data.frame(km3$centers), aes(Gesamtsumme, TNK), size = 3)
```

This doesn't work really well. Lets try the factoextra package. Maybe we can find something in there which helps and make it more convinient.

## Factoextra package

### Load package

```{r}
library(FactoMineR)
library(factoextra)
```


### PCA

Let's do a principle component analyses to extract only the needed variables to explain 85-90 percent of the varriance.

```{r}
df1_pca <- PCA(df1[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")],  graph = FALSE)

```
 
 Let's have a look on the eigenvalues and eigenvariances.
 
```{r}
get_eig(df1_pca)
```
  
  We can see that we can fit with 86 % if we only choose 5 dimensions. Let's visualize it to have a better look at it.
  
```{r}
fviz_screeplot(df1_pca, addlabels = TRUE, ylim = c(0, 50))
```
  
  Let's look into the variables. Which one explained most of the variance. Let's extract the results for the variables.
  
```{r}
var <- get_pca_var(df1_pca)
var
```
  
We can print the head of this atributes. First the coordinates, second the contribution.

```{r}
head(var$coord)
```

The coordinates explain the direction and the contribution explained the length of the arrows

```{r}
head(var$contrib)
```

Let's visualize it.

```{r}
fviz_pca_var(df1_pca, col.var = "black")
```

Or with this one.

```{r}
library("corrplot")
corrplot(var$cos2, is.corr=FALSE)
```

We can see that the tempretures\
(TXK = Days maximum of airtemperatur in 2m hight in °c,\
 TNK = Days minimum of airtemperatur in 2m hight in °c,\
 TMK = Days mean temperature,\
 TGK = Days minimum of airtemperature in 5 cm highth)\
 and the mean of days relative humidity = UPM and the mean of days vapor pressure = VPM explained most of the first dimension.
 So we have to delete some of the columns to handle the data better. At least let's try the bipolar plot.
 
```{r}
fviz_pca_biplot(df1_pca)
```
 
 Now we can see all the different customers and which variable fit to the customers. Each group of points are one selling day with its explicit weather and each point are one customer of this selling day which bought a different amount. We should now minimize the dimensions based on our pca to get a easier handling for the data. 
 
### Clustering
 
 Let's try to cluster again. But this time we will scale our data and we will use factoextra package.
 
```{r}
# 1. Loading and preparing data
df1_scaled <- scale(df1[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")])
# 2. Find the optimal number of clusters
fviz_nbclust(df1_scaled, kmeans, method = "gap_stat")
# 3. Compute k-means
km1_scaled <- kmeans(scale(df1[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")]), 5, nstart = 25)
# 4. Visualize
fviz_cluster(km1_scaled, data = df1_scaled,
             palette = c("#00AFBB","#2E9FDF", "#E7B800", "#FC4E07", "#000000"),
             ggtheme = theme_minimal(),
             main = "kMeans Clustering"
             )
```
 
 It looks like we have clustered the days with the same weather. Let's add these clusters to the original data.
 
```{r}
df1 <- bind_cols(df1, km_right = as.factor(km1_scaled$cluster))
```
 
 Let's plot some information with the addional cluster column.
 
```{r}
df1 %>%
  distinct(Name, Vorname, Postleitzahl, km_right) %>%
  count(Postleitzahl)

df1 %>%
  distinct(Name, Vorname, Postleitzahl, km_right) %>%
  count(km_right)

df1 %>%
  group_by(date, km_right) %>%
  summarise(verdient = sum(Gesamtbrutto)) %>%
  ggplot(aes(x = date, y = verdient, colour = km_right )) +
  geom_point()
  
```
 
 I couldn't find some good plot with this additional cluster information.
 
```{r}
df1 %>%
  group_by(Name, Vorname) %>%
  summarise(ausgegeben = sum(Gesamtbrutto)) %>%
  arrange(desc(ausgegeben))
```
 
 I come to an end and my knowledge out of this analyses is that there no dependencies between the weather and the customers because lots of customers had serveral clusters. I think that the amount of data could be more. I should try this analyses on my selling data. Maybe I can find there some dependencies between overall selling and weather. And there should be a method to weight some variables more than others. 
