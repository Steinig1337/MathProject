---
title: "MathProject"
author: "F D"
date: "26 12 2019"
output:
  rmdformats::readthedown:
    highlight: kate
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Load the packages

```{r include=FALSE}
library(tidyverse)
library(readxl)
library(shiny)
library(shinythemes)
library(lubridate)
```

# Executive summery



# Welcome to the project for the math class

I will add my customer data to the weather data and i will try to do a pca (pricipal component analyse), some clustering(kmeans, k-nearest neightbour) and a linear regression on the data. I want to find some relationsships between selling of a product and the weather or some other relationship i dont know. So first of all i will combine the data into one big data frame. To do that we have to load all the different data and do some data wrangling. 

## Questions



# Data Wrangling

## Load data

```{r}
selling_q3 <- read_xls("Data/Auszahlungen_2019-07-01_2019-09-30.xls")
selling_oct <- read_xls("Data/Auszahlungen_2019-10-01_2019-10-31.xls")
selling_nov <- read_xls("Data/Auszahlungen_2019-11-01_2019-11-30.xls")
product_q3 <- read_xls("Data/Verkaufe_pro_Angebot_2019-07-01_2019-09-30.xls")
product_oct <- read_xls("Data/Verkaufe_pro_Angebot_2019-10-01_2019-10-31.xls")
product_nov <- read_xls("Data/Verkaufe_pro_Angebot_2019-11-01_2019-11-30.xls")
customers_q3 <- read_xls("Data/Verkaufe_Rechnungen_2019-07-01_2019-09-30.xls")
customers_oct <- read_xls("Data/Verkaufe_Rechnungen_2019-10-01_2019-10-31.xls")
customers_nov <- read_xls("Data/Verkaufe_Rechnungen_2019-11-01_2019-11-30.xls")
weather <- read_delim("Data/produkt_klima_tag_20180704_20200104_02564.txt", ";", escape_double = FALSE, trim_ws = TRUE)
```

I loaded some data of my customers, my selling in generell and my selling of each product. So the selling data frame is for the generall selling informations. The produkt data frame is for the informations about each product and how often it got sold. The last data frame is called customers and it holds informations about the customers. Where they are from and how much they bought. And i forgot the weather data frame. It holds the weather information for each day.

## Combine the other months with the first three

To get the whole data we have to combine all the different months.

```{r}
customers <- list(customers_q3, customers_oct, customers_nov) %>%
  bind_rows()
product <- list(product_q3, product_oct, product_nov) %>%
  bind_rows()
selling <- list(selling_q3, selling_oct, selling_nov) %>%
  bind_rows()
```

## Delete the rest

Let's delete the data frames which aren't needed anymore. So the environment is tidied up.

```{r}
rm(customers_q3, customers_oct, customers_nov, product_q3, product_oct, product_nov, selling_q3, selling_oct, selling_nov)
```


## Delete columns which aren't needed

We have to tidy up some columns which are totally useless or the information is doubled.

```{r}
customers <- customers %>%
  select(-`Summe MwSt.`, -`Nummer der Schwärmerei`, -`Summe netto`)
product <- product %>%
  select(-`Summe MwSt.`, -`Summe netto`, -Produktkategorie, -`Produkt Unterkategorie`)
selling <- selling %>%
  select(-`Verkäufe - Mehrwertsteuer`, -`Verkäufe - Summe netto`, -`Servicegebühr - Mehrwertsteuersatz 19%`, -`Servicegebühr - wenn der Rechnungsempfänger die MwSt. nicht in Rechnung stellt`, -`Einkäufe - Summe netto`, -`Einkäufe - Mehrwertsteuer`)
weather <- weather %>%
  select(-STATIONS_ID, -QN_3, -QN_4, -SHK_TAG, -eor, -SDK)
```


## Replace different product names

Because i changed the product names in november i have to replace some product names so the same products have the same names.

```{r}
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Radieschen rot Microgreens unverpackt 40g", "Radieschen rot Microgreens unverpackt (1 × 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Kohlrabi rot Microgreens", "Kohlrabi rot Microgreens unverpackt (1 x 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("Brokkoli Microgreens unverpackt 40g - 40 g", "Brokkoli Microgreens unverpackt (1 x 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("Rote Bete Microgreens - 40 g", "Rote Bete Microgreens unverpackt (1 × 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Mizuna Microgreens unverpackt", "Mizuna Microgreens unverpackt (1 x 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Bockshornklee Microgreens unverpackt", "Bockshornklee Microgreens unverpackt (1 x 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Daikon Rettich unverpackt 40g", "Daikon Rettich unverpackt (1 × 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Radieschen rot Microgreens unverpackt 100g", "Radieschen rot Microgreens unverpackt (1 × 100 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Sonnenblumen Microgreens unverpackt 100g", "Sonnenblumen Microgreens unverpackt (1 × 100 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("1 Sonnenblumen Microgreens unverpackt 40g", "Sonnenblumen Microgreens unverpackt (1 × 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("20g Koriander Microgreens unverpackt 20g", "Koriander Microgreens unverpackt (1 × 20 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("Erbsen Microgreens unverpackt 40g - 40 g", "Erbsen Microgreens unverpackt (1 × 40 g)")
product$Produktname <- product$Produktname %>%
  str_replace_all("Senf Microgreens unverpackt 40g (1 × 40 g)", "Senf Microgreens unverpackt (1 × 40 g)")
```


## Test of product names

```{r}
product %>%
  distinct(Produktname) %>%
  arrange(Produktname)
```

We see that there is still one name doubled. But i could't find the error so we have to use it like this.

## Lets replace different offernumbers

Here we have the same problem like for the productnames. So we have to replace some numbers that we get a equal number for the same product. If we don't do that we have lot's of different numbers for the same product and the analyse does't work very well.

```{r}
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("BMICR.fdaf.1", "BMU40.g3va.1")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("DRUNV.fino.1", "DRU40.g3vj.1")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("RROT.f9et.1", "RRMU4.g3vu.1")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("RRU10.fpiv.1", "RRMU4.g3vu.2")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("RRMU1.g3vr.2", "RRMU4.g3vu.2")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("SENF.f9ew.1", "SMU40.g3vw.1")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("SMUNV.finu.1", "SMU40.g3w1.1")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("SMU10.g3vz.1", "SMU40.g3w1.2")
product$Angebotsnummer <- product$Angebotsnummer %>%
  str_replace_all("SMU10.foby.1", "SMU40.g3w1.2")


```

## Test the offernumbers

```{r}
product %>%
  distinct(Angebotsnummer, Produktname) %>%
  arrange(Produktname)
```

As you can see we have now only one offernumber for one product.

## Use lubridate to manipulate the date column

We have to have equal date columns to join the selling data with the weather data. So i use lubridate to change the date column to make easier to join the data.

```{r}
# customers$`Datum der Verteilung` <- ymd_hms(customers$`Datum der Verteilung`) maybe we have to extract only the date
weather$MESS_DATUM <- ymd(weather$MESS_DATUM)

customers <- customers %>%
  mutate(date = date(customers$`Datum der Verteilung`))
product <- product %>%
  mutate(date = date(product$`Datum der Verteilung`))
selling <- selling %>%
  mutate(date = date(selling$`Datum der Verteilung`))
weather <- weather %>%
  mutate(date = date(weather$MESS_DATUM))
```


## Let's add some weather data to the selling informations.

Let's add the weather information for the selling days. Maybe there is a correlation between bad weather and bad selling days. But we will join it in a new data frame so we can analyse the date with weather informations and without.

```{r}
customers_weather <- left_join(customers, weather, by = "date") 
# by = c("column1", "column2") so i don't have to create a new column with is equal in every data frame
product_weather <- left_join(product, weather, by = "date")
selling_weather <- left_join(selling, weather, by = "date")
```


## Let's have a look on the products

```{r}
product %>%
  group_by(Produktname) %>%
  summarise(Verkauft = sum(Menge), Erloes = sum(Gesamtbrutto)) %>%
  ggplot(aes(x = reorder(Produktname, Erloes), y = Verkauft, fill = Erloes)) +
  geom_col() +
  coord_flip()
```

# Statistical analysis

I will try some methods we discussed in class on my data. After that I will look on the result and decide what to do next. Maybe we will get some nice dependencies or maybe not. First i will do some clustering with kmeans and k-Nearest Neighbour. After that i will try a principle component analysis and at least a linear regression. Hopefully i will learn something about my customers and we will get some interesting insights.



## kmeans clustering

Let's try to find some interesting clusters to discribe customer groups or something else. First i will try to get some clusters with the combined customer_weather data. We have to use numeric columns for clusters. So we have to explicid say with columns are used for the clustering. So let's try every column which is numeric. To view the clusters we can use ggplot with a 2d plot.

```{r}
km1 <- kmeans(x = customers_weather[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")], centers = 2)

df1 <- customers_weather

df1 <- bind_cols(df1, km = as.factor(km1$cluster))

df1 %>% 
  ggplot() +
  geom_point(aes(Gesamtbrutto, TNK, color = km)) +
  geom_point(data = as.data.frame(km1$centers), aes(Gesamtbrutto, TNK), size = 3)
```

We can see that this model doens't work very well. Lets try the others.

```{r}
km2 <- kmeans(x = product_weather[,c("Einzelpreis netto", "Menge", "Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")], centers = 2)

df2 <- product_weather

df2 <- bind_cols(df2, km = as.factor(km2$cluster))

df2 %>% 
  ggplot() +
  geom_point(aes(Gesamtbrutto, TNK, color = km)) +
  geom_point(data = as.data.frame(km2$centers), aes(Gesamtbrutto, TNK), size = 3)
```

Same visualization as the plot before.

```{r}
km3 <- kmeans(x = selling_weather[,c("Verkäufe - Gesamtbetrag", "Einkäufe - Gesamtbetrag", "Gesamtsumme", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")], centers = 3)

df3 <- selling_weather

df3 <- bind_cols(df3, km = as.factor(km3$cluster))

df3 %>% 
  ggplot() +
  geom_point(aes(Gesamtsumme, TNK, color = km)) +
  geom_point(data = as.data.frame(km3$centers), aes(Gesamtsumme, TNK), size = 3)
```

This doesn't work really well. Lets try the factoextra package. Maybe we can find something in there which helps and make it more convinient.

## Factoextra package

### Load package

```{r include=FALSE}
library(FactoMineR)
library(factoextra)
library(corrplot)
```


### PCA

Let's do a principle component analyses to extract only the needed variables to explain 85-90 percent of the varriance.

```{r}
df1_pca <- PCA(df1[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")],  graph = FALSE)

```
 
 Let's have a look on the eigenvalues and eigenvariances.
 
```{r}
get_eig(df1_pca)
```
  
  We can see that we can fit with 86 % if we only choose 5 dimensions. Let's visualize it to have a better look at it.
  
```{r}
fviz_screeplot(df1_pca, addlabels = TRUE, ylim = c(0, 50))
```
  
  Let's look into the variables. Which one explained most of the variance. Let's extract the results for the variables.
  
```{r}
var <- get_pca_var(df1_pca)
var
```
  
We can print the head of this atributes. First the coordinates, second the contribution.

```{r}
head(var$coord)
```

The coordinates explain the direction and the contribution explained the length of the arrows

```{r}
head(var$contrib)
```

Let's visualize it.

```{r}
fviz_pca_var(df1_pca, col.var = "black")
```

Or with this one.

```{r}
corrplot(var$cos2, is.corr=FALSE)
```

We can see that the tempretures\
(TXK = Days maximum of airtemperatur in 2m hight in °c,\
 TNK = Days minimum of airtemperatur in 2m hight in °c,\
 TMK = Days mean temperature,\
 TGK = Days minimum of airtemperature in 5 cm highth)\
 and the mean of days relative humidity = UPM and the mean of days vapor pressure = VPM explained most of the first dimension.
 So we have to delete some of the columns to handle the data better. At least let's try the bipolar plot.
 
```{r}
fviz_pca_biplot(df1_pca)
```
 
 Now we can see all the different customers and which variable fit to the customers. Each group of points are one selling day with its explicit weather and each point are one customer of this selling day which bought a different amount. We should now minimize the dimensions based on our pca to get a easier handling for the data. 
 
### Clustering
 
 Let's try to cluster again. But this time we will scale our data and we will use factoextra package. Here without using the results of the pca.
 
```{r}
# 1. Loading and preparing data
df1_scaled <- scale(df1[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")])
# 2. Find the optimal number of clusters
fviz_nbclust(df1_scaled, kmeans, method = "gap_stat")
# 3. Compute k-means
km1_scaled <- kmeans(scale(df1[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")]), 5, nstart = 25)
# 4. Visualize
fviz_cluster(km1_scaled, data = df1_scaled,
             palette = c("#00AFBB","#2E9FDF", "#E7B800", "#FC4E07", "#000000"),
             ggtheme = theme_minimal(),
             main = "kMeans Clustering"
             )
```
 
 It looks like we have clustered the days with the same weather. Let's add these clusters to the original data.
 
```{r}
df1 <- bind_cols(df1, km_right = as.factor(km1_scaled$cluster))
```
 
 Let's plot some information with the addional cluster column.
 
```{r}
df1 %>%
  distinct(Name, Vorname, Postleitzahl, km_right) %>%
  count(Postleitzahl)

df1 %>%
  distinct(Name, Vorname, Postleitzahl, km_right) %>%
  count(km_right)

df1 %>%
  group_by(date, km_right) %>%
  summarise(verdient = sum(Gesamtbrutto)) %>%
  ggplot(aes(x = date, y = verdient, colour = km_right )) +
  geom_point()
  
```
 
 I couldn't find some good plot with this additional cluster information.
 
```{r}
df1 %>%
  group_by(Name, Vorname) %>%
  summarise(ausgegeben = sum(Gesamtbrutto)) %>%
  arrange(desc(ausgegeben))
```
 
 Now i try to look at the average of the attributes of a cluster. Maybe we can define the clusters.
 
```{r}
df1 %>%
  group_by(km_right) %>%
  summarize(avg_Gesamtbrutto = mean(Gesamtbrutto), avg_FX = mean(FX), avg_FM = mean(FM), avg_RSK = mean(RSK), avg_RSKF = mean(RSKF), avg_NM = mean(NM), avg_VPM = mean(VPM), avg_PM = mean(PM), avg_TMK = mean(TMK), avg_UPM = mean(UPM), avg_TXK = mean(TXK), avg_TNK = mean(TNK), avg_TGK = mean(TGK))
```
 
 
 I come to an end and my knowledge out of this analyses is that there no dependencies between the weather and the customers because lots of customers had serveral clusters. I think that the amount of data could be more. I should try this analyses on my selling data. Maybe I can find there some dependencies between overall selling and weather. And there should be a method to weight some variables more than others. We can see in the table above that we get 5 clusters. They differences in temperature and humidity. Let's try to use our result out of the pca to minimalize the attributes. So it is more convinient and easier to interpretate.
 
```{r}
# 1. Loading and preparing data
df1_scaled <- scale(df1[,c("Gesamtbrutto", "TXK", "TNK", "VPM", "TMK", "UPM", "TGK")])
# 2. Find the optimal number of clusters
fviz_nbclust(df1_scaled, kmeans, method = "gap_stat")
fviz_nbclust(df1_scaled, kmeans, method = "wss")
# 3. Compute k-means
km1_scaled <- kmeans(scale(df1[,c("Gesamtbrutto", "TXK", "TNK", "VPM", "TMK", "UPM", "TGK")]), 4, nstart = 25)
# 4. Visualize
fviz_cluster(km1_scaled, data = df1_scaled,
             palette = c("#00AFBB","#2E9FDF", "#E7B800", "#FC4E07"),
             ggtheme = theme_minimal(),
             main = "kMeans Clustering"
             )

```
 
 Add this clusters to the table.
 
```{r}
df1 <- bind_cols(df1, km_right2 = as.factor(km1_scaled$cluster))
```
 
  Let's have a look on the average values.
 
```{r}
table1 <- df1 %>%
  group_by(km_right2) %>%
  summarize(avg_Gesamtbrutto = mean(Gesamtbrutto), avg_VPM = mean(VPM), avg_TMK = mean(TMK), avg_UPM = mean(UPM), avg_TXK = mean(TXK), avg_TNK = mean(TNK), avg_TGK = mean(TGK))

DT::datatable(table1)
```
 
 
# Statistical analysis app

Now i will try to program an analysis app for all datasets. So this app needs some chooseable datasets and than there have to be some options for the analysis. Let's start and see how far we get.

## Load packages

```{r include=FALSE}
library(plotly)
library(shiny)
library(DT)
library(gridExtra)
```

## Program an application

```{r}
analysis <- c("pca", "k-means")

shinyApp(
  
ui <- fluidPage(
  titlePanel("Interactive analysis application"),
  sidebarLayout(
    sidebarPanel(
      # conditionalPanel(
      #   'input.dataset === "customers_weather"',
        selectInput("select1", "Select your analysis", analysis),
        #sliderInput("slider1", label = h3("Choose your number of clusters"), min = 1, max = 15, value = 2)
        uiOutput("ui1")
      # ),
      # conditionalPanel(
      #   'input.dataset === "selling_weather"',
      #   selectInput("select1", "Select your analysis", analysis),
      #   #sliderInput("slider1", label = h3("Choose your number of clusters"), min = 1, max = 15, value = 2)
      #   uiOutput("ui2")
      # ),
      # conditionalPanel(
      #   'input.dataset === "product_weather"',
      #   selectInput("select1", "Select your analysis", analysis),
      #   #sliderInput("slider1", label = h3("Choose your number of clusters"), min = 1, max = 15, value = 2)
      #   uiOutput("ui3")
      # )
    ),
    
      # Mainpanel with 3 different tabs and plots
    
    mainPanel(
      tabsetPanel(
        id = "dataset",
        tabPanel(
          "customers_weather",
          id = "customers_weather",
          dataTableOutput("table1"),
          plotlyOutput("customers_plot1"),
          plotlyOutput("customers_plot2"),
          plotOutput("customers_plot3")
        ),
        tabPanel(
          "selling_weather",
          id = "selling_weather",
          dataTableOutput("table2"),
          plotlyOutput("selling_plot1"),
          plotlyOutput("selling_plot2"),
          plotOutput("selling_plot3")
        ),
        tabPanel(
          "product_weather",
          id = "product_weather",
          dataTableOutput("table3"),
          plotlyOutput("product_plot1"),
          plotlyOutput("product_plot2"),
          plotOutput("product_plot3")
        )
      )
    )
    
  )
  
),

server <- function(input, output, session) {
  
 
    # reactive ui function which expant more options if you change the analysis
  
  output$ui1 <- renderUI({
    if (is.null(input$select1))
      return()
    switch (input$select1,
      "pca" = NULL,
      "k-means" = sliderInput("slider1", label = h3("Choose your number of clusters"), min = 1, max = 15, value = 2)
    )
  })
  
    # the reactive table switcher which switches the data sets if you switch the tabs
    # it worked but only without the reactive ui function
  
  table_switcher <- reactive({
    switch (input$dataset,
      "customers_weather" = datatable(customers_weather),
      "selling_weather" = datatable(selling_weather),
      "product_weather" = datatable(product_weather)
    )
  })
  
    # some tries to find the error
  
  # output$ui2 <- renderUI({
  #   if (is.null(input$select1))
  #     return()
  #   switch (input$select1,
  #     "pca" = NULL,
  #     "k-means" = sliderInput("slider1", label = h3("Choose your number of clusters"), min = 1, max = 15, value = 2)
  #   )
  # })
  # output$ui3 <- renderUI({
  #   if (is.null(input$select1))
  #     return()
  #   switch (input$select1,
  #     "pca" = NULL,
  #     "k-means" = sliderInput("slider1", label = h3("Choose your number of clusters"), min = 1, max = 15, value = 2)
  #   )
  # })  
  
    # reactive functions for the customers data analysis
    # it shows different plots dependend on what you have choosen
    # you could do it more compact with a switch function wich is based on the tabs you choose
    # so you would only need 3 reactive switch functions for the three plots and 3 switch functions for the 3 different data sets instead of 9 functions
  
  switcher1 <- reactive({
    switch (input$select1,
      "pca" = {
        pca_cw <- PCA(customers_weather[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")],  graph = FALSE)
        fviz_screeplot(pca_cw, addlabels = TRUE, ylim = c(0, 50))
      },
      "k-means" = {
        customers_weather_scaled <- scale(customers_weather[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")])
        fviz_nbclust(customers_weather_scaled, kmeans, method = "gap_stat")
      }
    )
  })
  
  switcher2 <- reactive({
    switch (input$select1,
      "pca" = {
        pca_cw <- PCA(customers_weather[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")],  graph = FALSE)
        fviz_pca_var(pca_cw, col.var = "black")
      },
      "k-means" = {
        customers_weather_scaled <- scale(customers_weather[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")])
        km1_scaled <- kmeans(scale(customers_weather[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")]), input$slider1, nstart = 25)
        fviz_cluster(km1_scaled, data = customers_weather_scaled,
                     ggtheme = theme_minimal(),
                     main = "kMeans Clustering"
                     )
      }
    )
  })
  
  switcher3 <- reactive({
    switch (input$select1,
      "pca" = {
        pca_cw <- PCA(customers_weather[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")],  graph = FALSE)
        var_cw <- get_pca_var(pca_cw)
        corrplot(var_cw$cos2, is.corr=FALSE)
      },
      "k-means" = NULL
    )
  })
  
    # reactive functions for the selling data analysis
    # it shows different plots dependend on what you have choosen
  
  switcher4 <- reactive({
    switch (input$select1,
      "pca" = {
        pca_sw <- PCA(selling_weather[,c("Verkäufe - Gesamtbetrag", "Einkäufe - Gesamtbetrag", "Gesamtsumme", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")],  graph = FALSE)
        fviz_screeplot(pca_sw, addlabels = TRUE, ylim = c(0, 50))
      },
      "k-means" = {
        selling_weather_scaled <- scale(selling_weather[,c("Verkäufe - Gesamtbetrag", "Einkäufe - Gesamtbetrag", "Gesamtsumme", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")])
        fviz_nbclust(selling_weather_scaled, kmeans, method = "gap_stat")
      }
    )
  })
  
  switcher5 <- reactive({
    switch (input$select1,
      "pca" = {
        pca_sw <- PCA(selling_weather[,c("Verkäufe - Gesamtbetrag", "Einkäufe - Gesamtbetrag", "Gesamtsumme", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")],  graph = FALSE)
        fviz_pca_var(pca_sw, col.var = "black")
      },
      "k-means" = {
        selling_weather_scaled <- scale(selling_weather[,c("Verkäufe - Gesamtbetrag", "Einkäufe - Gesamtbetrag", "Gesamtsumme", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")])
        km2_scaled <- kmeans(scale(selling_weather[,c("Verkäufe - Gesamtbetrag", "Einkäufe - Gesamtbetrag", "Gesamtsumme", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")]), input$slider1, nstart = 25)
        fviz_cluster(km2_scaled, data = selling_weather_scaled,
                     ggtheme = theme_minimal(),
                     main = "kMeans Clustering"
                     )
      }
    )
  })
  
  switcher6 <- reactive({
    switch (input$select1,
      "pca" = {
        pca_sw <- PCA(selling_weather[,c("Verkäufe - Gesamtbetrag", "Einkäufe - Gesamtbetrag", "Gesamtsumme", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")],  graph = FALSE)
        var_sw <- get_pca_var(pca_sw)
        corrplot(var_sw$cos2, is.corr=FALSE)
      },
      "k-means" = NULL
    )
  })
  
    # reactive functions for the product data analysis
    # it shows different plots dependend on what you have choosen
  
  switcher7 <- reactive({
    switch (input$select1,
      "pca" = {
        pca_pw <- PCA(product_weather[,c("Einzelpreis netto", "Menge", "Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")],  graph = FALSE)
        fviz_screeplot(pca_pw, addlabels = TRUE, ylim = c(0, 50))
      },
      "k-means" = {
        product_weather_scaled <- scale(product_weather[,c("Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")])
        fviz_nbclust(product_weather_scaled, kmeans, method = "gap_stat")
      }
    )
  })
  
  switcher8 <- reactive({
    switch (input$select1,
      "pca" = {
        pca_pw <- PCA(product_weather[,c("Einzelpreis netto", "Menge", "Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")],  graph = FALSE)
        fviz_pca_var(pca_pw, col.var = "black")
      },
      "k-means" = {
        product_weather_scaled <- scale(product_weather[,c("Einzelpreis netto", "Menge", "Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")])
        km3_scaled <- kmeans(scale(product_weather[,c("Einzelpreis netto", "Menge", "Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")]), input$slider1, nstart = 25)
        fviz_cluster(km3_scaled, data = product_weather_scaled,
                     ggtheme = theme_minimal(),
                     main = "kMeans Clustering"
                     )
      }
    )
  })
  
  switcher9 <- reactive({
    switch (input$select1,
      "pca" = {
        pca_pw <- PCA(product_weather[,c("Einzelpreis netto", "Menge", "Gesamtbrutto", "TXK", "TNK", "FX", "FM", "RSK", "RSKF", "NM", "VPM", "PM", "TMK", "UPM", "TGK")],  graph = FALSE)
        var_pw <- get_pca_var(pca_pw)
        corrplot(var_pw$cos2, is.corr=FALSE)
      },
      "k-means" = NULL
    )
  })
  
    # output of the data tables in with a reactive function
  
  output$table <- renderDataTable({
    table_switcher()
  })
  
    # Output of the data tables, you could use it as an input to do other stuff
    # i tried to use only one function but it doesn't worked very well
  
  output$table1 <- renderDataTable({
    datatable(customers_weather)
  })
  output$table2 <- renderDataTable({
    datatable(selling_weather)
  })
  output$table3 <- renderDataTable({
    datatable(product_weather)
  })
  
    # output of the customers analysis
    # in there is a function which swiches between pca and cluster analysis
  
  output$customers_plot1 <- renderPlotly({
    switcher1()
  })
  output$customers_plot2 <- renderPlotly({
    switcher2()
  })
    output$customers_plot3 <- renderPlot({
    switcher3()
  })
    
    # i tried to do it reactive with a function so i dont have to use 9 outputs but it didn't work
    # output of the selling analysis
    # in there is a function which swiches between pca and cluster analysis
    
  output$selling_plot1 <- renderPlotly({
    switcher4()
  })
  output$selling_plot2 <- renderPlotly({
    switcher5()
  })
    output$selling_plot3 <- renderPlot({
    switcher6()
  })
    
    # output of the product analysis
    # in there is a function which swiches between pca and cluster analysis
    
  output$product_plot1 <- renderPlotly({
    switcher7()
  })
  output$product_plot2 <- renderPlotly({
    switcher8()
  })
    output$product_plot3 <- renderPlot({
    switcher9()
  })
  
},
options = list(height = 1500)
)
```

## Reflection

The application is nice and it shows you easiely the results of this two methods. Now i could implement some more methods and options. For example some different elbow methods, different clustering, the number of iterations or a complete new method like the linear regression. However, it tooks some hours to type this code. I would be really happy if i could get the code smaller and more compressed but that doesn't worked out well. You can overview the results and see that there some variables with i could delete because there variance is really low. To see some informations out of the clustering we have to do some more plots with different questionaries. The other two data sets had different cluster and maybe there are some good insights in the clustering. To get relevant information out of unsorted and not explored data you always have to offer some time to find the right questions and to get the results. I think if i offer one or two more weeks into this project i could find some interresting informations.
